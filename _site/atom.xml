<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Andrew Grathwohl</title>
 <link href="https://grathwohl.me/atom.xml" rel="self"/>
 <link href="https://grathwohl.me/"/>
 <updated>2020-09-21T13:38:26-04:00</updated>
 <id>https://grathwohl.me</id>
 <author>
   <name></name>
   <email></email>
 </author>

 
 <entry>
   <title>Musicians: Want Money? Do Work.</title>
   <link href="https://grathwohl.me/2020/09/21/music-revenues"/>
   <updated>2020-09-21T08:14:04-04:00</updated>
   <id>https://grathwohl.me/2020/09/21/Music-Revenues</id>
   <content type="html">&lt;blockquote&gt;
  &lt;p&gt;Musicians everywhere want more - and they want it yesterday. But the answer has been here for two decades.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Musicians are complaining about the raw deals they are getting from streaming. That’s no surprise to anybody who has dealt with “DSPs” such as Spotify, Apple Music, and Deezer. Anyone who’s dealt with these services knows what little actual revenue they can expect to receive. However, isn’t it curious that &lt;a href=&quot;https://podcasters.spotify.com/&quot;&gt;all&lt;/a&gt; &lt;a href=&quot;https://podcasts.apple.com/us/genre/podcasts/id26&quot;&gt;three&lt;/a&gt; of these &lt;a href=&quot;https://www.stitcher.com/&quot;&gt;companies&lt;/a&gt; also operate in the podcasting realm, where these kinds of complaints are rarely ever heard?&lt;/p&gt;

&lt;h2 id=&quot;streaming-royalties&quot;&gt;Streaming Royalties&lt;/h2&gt;

&lt;p&gt;Spotify is known to pay an average of &lt;strong&gt;$0.004&lt;/strong&gt; per stream. That’s four-tenths of one cent per listen.&lt;/p&gt;

&lt;p&gt;Using the Spotify Royalty Calculator at &lt;a href=&quot;https://tunemunk.com/spotify-royalty-calculator/&quot;&gt;tunemunk&lt;/a&gt;, it’s easy to visualize how tough it is for a musician to make a decent living wage with their art when dealing with DSPs as their primary revenue source.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/tm.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are very few musicians in the entire universe that can afford to create content for streaming services alone. Despite this, musicians work hard to ensure their releases are well-mixed, mastered artfully, and come paired with beautiful cover art.&lt;/p&gt;

&lt;p&gt;The same cannot be said for podcasters, yet they’re cleaning up!&lt;/p&gt;

&lt;h2 id=&quot;podcasts-terrible-quality--terrific-earnings&quot;&gt;Podcasts: Terrible Quality &amp;amp; Terrific Earnings&lt;/h2&gt;

&lt;p&gt;Audio engineers, back me up here: most podcasts sound awful. COVID has done little to help this problem, now that even fewer studios are in-use today than before. Today, Zoom and Facetime calls have become the norm, extending past podcasting and into the realm of other ad-supported media formats like broadcast television and local AM/FM radio.&lt;/p&gt;

&lt;p&gt;So, what are podcasters earning as they are literally &lt;em&gt;phoning it in&lt;/em&gt;? Musicians, prepare to be envious.&lt;/p&gt;

&lt;p&gt;A podcaster whose work performs just as well as our example streaming musician from above, earns more than &lt;strong&gt;ten thousand dollars&lt;/strong&gt; per episode. That, on its own, is more than &lt;strong&gt;double&lt;/strong&gt; the monthly income of the musician.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/tm2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This works out to a yearly take-home of &lt;strong&gt;$128,000&lt;/strong&gt; for our podcaster. And we’re not even done.&lt;/p&gt;

&lt;h3 id=&quot;expenses&quot;&gt;Expenses&lt;/h3&gt;

&lt;p&gt;Let’s now turn our attention to the expenses of today’s musicians and podcasters.&lt;/p&gt;

&lt;p&gt;Podcasts are typically made with a couple of mid-to-high quality microphones, equating to a one-time cost of between $1000-$3000. Then there’s the need for a decent audio interface and headphones for editing - another $500 or so. Frequently, &lt;a href=&quot;https://www.audacityteam.org/&quot;&gt;free and open source software&lt;/a&gt; is good enough for podcast editing. Overall, many peoples’ video game budgets are higher than what it costs to produce an above-average quality podcast.&lt;/p&gt;

&lt;p&gt;Musicians know there is a very different set of circumstances surrounding their chosen art. Maintaining a musician’s instrument, for example, is a labor of love, and can be quite expensive. Violinists routinely spend tens of thousands of dollars on their instruments over the years, oboists and bassoonists sit at home carving their own reeds regularly, and singers forgo air conditioning and hot coffee so as to protect their instrument. Don’t even get me started on the costs associated with becoming an analog synth nerd, or with entering the world of guitar amplifiers and effects pedals.&lt;/p&gt;

&lt;p&gt;Then there’s the actual product itself - the music. Music is often written and conceived of well in advance of when it gets recorded and tracked - unlike almost all podcasts. After tracking sessions are over, the resulting music tracks get passed around to several other stakeholders, who all leave their own mark on the musician’s original work. Audio is mixed, then mastered, in order to produce an enjoyable listening experience from beginning to end. Recordings with artifacts such as chair/foot sounds, microphone drop-outs, plosives, etc., are called out and those sections are re-recorded to ensure high audio fidelity. Musicians strive to get their tracks “just right.”&lt;/p&gt;

&lt;p&gt;All this effort is a natural extension of the musical lifestyle. Music is not simply a profession one takes on after graduating college - it’s often something one pursues &lt;em&gt;instead&lt;/em&gt; of college. Musicians had to begin playing their instrument well before this point in their lives, though, often studying prodigiously as children and forgoing many other kinds of activities during their youths as a result. Fidelity and technical accuracy are of tantamount importance to the musician, to the benefit of all listeners. That stuff takes &lt;em&gt;time&lt;/em&gt;, which musicians have all paid for up-front before even beginning their musical careers.&lt;/p&gt;

&lt;h2 id=&quot;tough-love&quot;&gt;Tough Love&lt;/h2&gt;

&lt;p&gt;We’ve thus established that musicians start out their careers with considerably more time invested into their art than podcasters. They spend far more money and reach a far higher degree of starting competence before venturing into their profession than podcasters. So, how come podcasters take home far more revenue for audio content than musicians?&lt;/p&gt;

&lt;p&gt;Musicians need to hear some tough love. The reason podcasting has far surpassed music earnings is because podcasters began doing all the hard work &lt;em&gt;after&lt;/em&gt; beginning their podcast. They never gave up their IP rights to “podcast labels” in weird contracts full of exclusivity and exit clauses. They learned how to edit, mix, and master their own recordings. They advocated for their own sponsorship deals, their own content policies, and even their own music assets - because the musicians’ ancient labels are too disorganized and contract-encumbered to integrate their products within the podcast world.&lt;/p&gt;

&lt;p&gt;Music is an ancient artform, just as ancient and important as oration. Both the human voice and the musical spirit have the means and the need to live on in the 21st century - and while podcasting has succeeded in attaining this goal for our voices, music seriously lags behind. Complacency is the cause, and the solution is to use modern, open standards, and free software, to reboot what it means to practice music, just like podcasting rebooted the art of oration.&lt;/p&gt;

&lt;h2 id=&quot;the-solution-is-self-ownership--courage&quot;&gt;The Solution Is Self-Ownership &amp;amp; Courage&lt;/h2&gt;

&lt;p&gt;Every musician who wants to monetize their art needs to begin by learning the skills they lack to be their own advocate.&lt;/p&gt;

&lt;p&gt;They must build their own web presence, learn how to produce their own music from beginning to end, and figure out how to organize and archive their artistic efforts in order to ensure their works live on with the changing times, no matter what new tech, challenges, and opportunities present themselves. They have to understand what they throw away by signing their rights away with a label, a representation group, or a publicist/agent.&lt;/p&gt;

&lt;p&gt;Though it is perfectly fine to use such services in genearl, the musician’s primary source of new music releases must be their own web infrastructure - not a SoundCloud page, a Bandcamp URL, or a Twitter account.  How? May I suggest…&lt;/p&gt;

&lt;h1 id=&quot;musicians-start-your-own-podcast-feed&quot;&gt;MUSICIANS: START YOUR OWN PODCAST FEED&lt;/h1&gt;

&lt;p&gt;Get some of that podcast monetization revenue. Seriously!&lt;/p&gt;

&lt;p&gt;I am beginning a new musical initiative that I have dubbed &lt;a href=&quot;https://sacreddata.github.io/HyperMusic/&quot;&gt;HyperMusic&lt;/a&gt; to research and promote this new music distribution idea.&lt;/p&gt;

&lt;p&gt;You can follow me on the HyperMusic journey at its associated &lt;a href=&quot;https://github.com/SacredData/HyperMusic&quot;&gt;GitHub page&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Browser-Based Audio Metering With the Web Audio API</title>
   <link href="https://grathwohl.me/2020/08/14/web-audio"/>
   <updated>2020-08-14T06:19:15-04:00</updated>
   <id>https://grathwohl.me/2020/08/14/Web-Audio</id>
   <content type="html">&lt;blockquote&gt;
  &lt;p&gt;How to drive your user interface with browser-based audio analysis&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The browser has gotten surprisingly good at processing real-time audio FFTs, thanks to the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API&quot;&gt;Web Audio API&lt;/a&gt;. As a result, incredible dynamic musical interfaces are now very achievable on the modern web, and it’s a heck of a lot easier than most developer resources would have you believe.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/SMWebAudio.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Above is a screengrab from my musical homepage, &lt;a href=&quot;https://multipli.city&quot;&gt;Multipli.city&lt;/a&gt;. There, I host all of my music from over the last ten years for free streaming and lossless download. One of the benefits to listening on the website is the unique visualization experience I offer listeners.&lt;/p&gt;

&lt;p&gt;This article will demonstrate how quick, easy, and powerful the Web Audio API can be, by taking you through the code that is needed to generate cool visualizations of your own.&lt;/p&gt;

&lt;h2 id=&quot;how-its-done&quot;&gt;How It’s Done&lt;/h2&gt;

&lt;p&gt;Building off of &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API#Creating_a_waveformoscilloscope&quot;&gt;some example code from MDN&lt;/a&gt;, I leverage the browser’s Web Audio API to instantiate an audio analysis node, which is easily done via JavaScript. Then, I hook it into my JavaScript audio playback library, the wonderfully fantastic &lt;a href=&quot;https://wavesurfer-js.org/&quot;&gt;Wavesurfer.js&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-the-analyser&quot;&gt;Setting Up the Analyser&lt;/h3&gt;

&lt;p&gt;Our analyser is setup via JavaScript:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Instantiate our web audio playback library, Wavesurfer in this case&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;wavesurfer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;WaveSurfer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;#player&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;cursorWidth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Grab the audio context from wavesurfer so we can insert an analysis node&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;audioCtx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;wavesurfer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ac&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Create the analyser node and give it a buffer size of 2048&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// which is a good compromise between performance and resource use&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;audioCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createAnalyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fftSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Setup the analyser to perform time domain analysis in real-time&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bufferLength&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;frequencyBinCount&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;dataArray&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Uint8Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bufferLength&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getByteTimeDomainData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;dataArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Don't forget to attach the analyser as a Wavesurfer filter&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;wavesurfer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;generating-the-canvas&quot;&gt;Generating the Canvas&lt;/h3&gt;

&lt;p&gt;In HTML, create a canvas:&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;canvas&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/canvas&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then grab that canvas’s context inside your JavaScript:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getElementById&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;2d&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point, we should have an audio analyser node and a canvas on which to draw. Now, we just need to create our animations and draw them onto the canvas.&lt;/p&gt;

&lt;h3 id=&quot;creating-a-groovy-function&quot;&gt;Creating A Groovy Function&lt;/h3&gt;

&lt;p&gt;We’ll now need to write a function that will draw our audio analysis information onto the canvas, in the form of an oscilloscope.&lt;/p&gt;

&lt;p&gt;Our &lt;code class=&quot;highlighter-rouge&quot;&gt;draw()&lt;/code&gt; function uses &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;requestAnimationFrame()&lt;/code&gt;&lt;/a&gt; to tell the browser that we want it to continuously execute for the purposes of rendering an animation &lt;strong&gt;(A)&lt;/strong&gt;. We then grab the current time domain data from the audio analyser node established previously &lt;strong&gt;(B)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Next, we use our &lt;code class=&quot;highlighter-rouge&quot;&gt;canvasCtx&lt;/code&gt; to set the properties for the line we are about to draw on the canvas &lt;strong&gt;(C)&lt;/strong&gt;. Once we’ve done this preliminary work, we are ready to work with our analyser’s buffered audio data. We start by looping through the captured audio and determining how high on the Y axis each item in the array ought to be to accurately render audio levels &lt;strong&gt;(D)&lt;/strong&gt;. We conclude the execution of our &lt;code class=&quot;highlighter-rouge&quot;&gt;draw()&lt;/code&gt; function by making our line on the canvas &lt;strong&gt;(E)&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// (A)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;requestAnimationFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// (B)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;analyser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getByteTimeDomainData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;dataArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// (C)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fillStyle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`rgb(0, 0, 0, &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)`&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fillRect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;strokeStyle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;#FFF&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;beginPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sliceWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bufferLength&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// (D)&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bufferLength&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;dataArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;128.0&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;moveTo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;drawColors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;drawColors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lineTo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;linewidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;lineWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sliceWidth&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// (E)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lineTo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;canvas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;canvasCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stroke&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Instead of an oscilloscope design, you could also try a frequency graph like the one MDN outlines &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API#Creating_a_frequency_bar_graph&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;some-best-practices&quot;&gt;Some Best Practices&lt;/h4&gt;

&lt;p&gt;When using &lt;code class=&quot;highlighter-rouge&quot;&gt;requestAnimationFrame()&lt;/code&gt; it is wise to capture its return value to a new variable, such as &lt;code class=&quot;highlighter-rouge&quot;&gt;animationId&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;animationId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;requestAnimationFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing this will allow you to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;cancelAnimationFrame()&lt;/code&gt; method on the window when you want to kill the animation:&lt;/p&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;wavesurfer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;finish&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;animationid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;cancelAnimationFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;animationId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;animationId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;undefined&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;Check out my public code &lt;a href=&quot;https://github.com/SacredData/pRoJEct-NeGYa/blob/master/_includes/player.html&quot;&gt;on GitHub&lt;/a&gt; for examples of where to take your new freaky audio visualizations!&lt;/p&gt;

&lt;p&gt;Live examples of this work are available at https://multipli.city&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Working with RTSP in FFmpeg</title>
   <link href="https://grathwohl.me/2020/06/23/rtsp-ffmpeg"/>
   <updated>2020-06-23T08:04:00-04:00</updated>
   <id>https://grathwohl.me/2020/06/23/RTSP-FFmpeg</id>
   <content type="html">&lt;p&gt;Recently, I’ve found myself situated among a &lt;a href=&quot;https://news.yahoo.com/whats-sound-not-just-york-025006561.html?soc_src=hl-viewer&amp;amp;soc_trk=tw&quot;&gt;great fireworks battle&lt;/a&gt; in Brooklyn, NY. As we continue to work out the details about the heightened fireworks activity across the United States, I felt it was important that I document and share my experience to contribute what I can to the ongoing conversation. So, I grabbed an old IP camera I had in a corner gathering dust, placed it outside on my fire escape, and fired it up to get a decent shot of the night sky in my neighborhood.&lt;/p&gt;

&lt;h2 id=&quot;ip-camera-trickiness&quot;&gt;IP Camera Trickiness&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/rtsp-control.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I did a little snooping around the control pannel software on the camera to discover that the RTSP protocol is used to transport the signal over ethernet. Being an FFmpeg stan, I was confident that I would be able to quickly grab and relay my &lt;a href=&quot;https://store.ui.com/collections/unifi-protect-cameras/products/unifi-video-camera-g3-dome&quot;&gt;UVC-G3-DOME&lt;/a&gt; signal right away. However, I failed to consider the contexts posed by the delivery transport. So, I was a bit surprised to discover that typing a typical &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg&lt;/code&gt; test command to ingest this camera’s feed resulted in some really weird error logs and a very corrupt video output.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ffmpeg &lt;span class=&quot;nt&quot;&gt;-re&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; rtsp://192.168.3.55:554/s0 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:v libx264 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:a libmp3lame test.mkv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/rtsp-corrupt.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above command would be adequate for testing the feed from software like &lt;code class=&quot;highlighter-rouge&quot;&gt;obs&lt;/code&gt; and from services like AWS Kinesis or Wowza Cloud. But this RTSP signal looked all sorts of weird when saved to disk.&lt;/p&gt;

&lt;h2 id=&quot;how-to-rtsp-in-ffmpeg&quot;&gt;How To RTSP in FFmpeg&lt;/h2&gt;

&lt;p&gt;Upon doing some research, I discovered that &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg&lt;/code&gt; has rich support for the &lt;a href=&quot;http://ffmpeg.org/ffmpeg-all.html#rtsp&quot;&gt;RTSP protocol&lt;/a&gt;, but as a result there are some specific FFmpeg flags that must be utilized that I’d failed to include in my previous test command. &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg&lt;/code&gt; requires the &lt;code class=&quot;highlighter-rouge&quot;&gt;-rtsp_transport&lt;/code&gt; input flag to declare the transport used by the camera - TCP in my camera’s case. This new test command produced a most agreeable output.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ffmpeg &lt;span class=&quot;nt&quot;&gt;-re&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rtsp_transport&lt;/span&gt; tcp &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; rtsp://192.168.3.55:554/s0 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:v libx264 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:a libmp3lame test.mkv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/rtsp-clean.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rtmp-relaying&quot;&gt;RTMP Relaying&lt;/h3&gt;

&lt;p&gt;My ultimate use case is a common one - I wanted to be able to record the live feed to local disk as well as relay the stream to a YouTube live stream RTMP endpoint. To accomplish this, &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg&lt;/code&gt; requires some specific output options declared to ensure compliance, as the direct RTSP signal from the camera is not in a compliant format.&lt;/p&gt;

&lt;p&gt;To resolve the RTMP compliance issue, I declared &lt;code class=&quot;highlighter-rouge&quot;&gt;-f flv -ar 44100 -r 30/1 -pix_fmt yuv420p&lt;/code&gt; as output options for the RTMP portion of  my &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg&lt;/code&gt; command. Declaring the format as FLV ensures the output bytestream is ordered in a way that is compliant with YouTube’s RTMP endpoint. Setting an explicit 44.1kHz sampling frequency for our audio guarantees full-spectrum audio while lowering overall output bitrate. And finally, enforcing the YUV420P pixel format ensures that your camera’s colors are correctly transformed to match YouTube’s color space.&lt;/p&gt;

&lt;p&gt;The full command now looks like this:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ffmpeg &lt;span class=&quot;nt&quot;&gt;-re&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rtsp_transport&lt;/span&gt; tcp &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; rtsp://192.168.3.55:554/s0 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:v copy &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:a copy stream_capture.mkv &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:v libx264 &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt;:v 3M &lt;span class=&quot;nt&quot;&gt;-minrate&lt;/span&gt;:v 3M &lt;span class=&quot;nt&quot;&gt;-maxrate&lt;/span&gt;:v 3M &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-bufsize&lt;/span&gt;:v 6M &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; 120 &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; 30/1 &lt;span class=&quot;nt&quot;&gt;-x264-params&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;keyint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;120:min-keyint&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;60 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;:a libmp3lame &lt;span class=&quot;nt&quot;&gt;-ar&lt;/span&gt; 44100 &lt;span class=&quot;nt&quot;&gt;-pix_fmt&lt;/span&gt; yuv420p rtmp://YOUTUBE_RTMP_URL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/fireworks.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That’s definitely a firework exploding a few feet away from my apartment building! Nice.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Best Free and Open Source Media Software</title>
   <link href="https://grathwohl.me/2020/05/27/foss-media-software"/>
   <updated>2020-05-27T11:51:00-04:00</updated>
   <id>https://grathwohl.me/2020/05/27/FOSS-Media-Software</id>
   <content type="html">&lt;p&gt;The FOSS ecosystem’s many benefits present only a few minor annoyances for sysadmins - the most significant of which is the need for research, as well as trial-and-error, when investigating new software to employ in your stack.&lt;/p&gt;

&lt;p&gt;If you are in need of suggestions for FOSS media software, this article is for you.&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;TLDR&lt;/h2&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pacman &lt;span class=&quot;nt&quot;&gt;-S&lt;/span&gt; sox mpv vapoursynth ffmpeg mkvtoolnix-cli graphicsmagick
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;audio&quot;&gt;Audio&lt;/h3&gt;

&lt;h4 id=&quot;sox-lgpl&quot;&gt;SoX (LGPL)&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://sox.sourceforge.net/&quot;&gt;SoX&lt;/a&gt; - or, Sound eXchange - is an LGPL application for processing sound. It supports every free (and some non-free) audio codecs, and employs by far the best resampler out there today, &lt;code class=&quot;highlighter-rouge&quot;&gt;libsoxr&lt;/code&gt;. Below, we see SoX totally annhilating expensive, proprietary “professional” audio software, Ableton Live, in a sampling rate conversion test.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/sox-src.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;containers&quot;&gt;Containers&lt;/h3&gt;

&lt;h4 id=&quot;matroska&quot;&gt;Matroska&lt;/h4&gt;

&lt;p&gt;If you want to stay sane working with media in the FOSS realm, you’ll need to be using &lt;a href=&quot;https://www.matroska.org/&quot;&gt;Matroska&lt;/a&gt;. A fully open and highly extensible container format, it is just about as free as free software gets.&lt;/p&gt;

&lt;p&gt;At a minimum, make sure you have &lt;a href=&quot;https://mkvtoolnix.download/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mkvtoolnix&lt;/code&gt;&lt;/a&gt; laying around for easy and flexible muxing, demuxing, and metadata tasks.&lt;/p&gt;

&lt;h3 id=&quot;images&quot;&gt;Images&lt;/h3&gt;

&lt;p&gt;For many years, the undisputed FOSS image processing king was &lt;code class=&quot;highlighter-rouge&quot;&gt;ImageMagick&lt;/code&gt;, however over the years the project has failed to address meaningful inefficiencies and bugs within the software. This spawned the &lt;code class=&quot;highlighter-rouge&quot;&gt;GraphicsMagick&lt;/code&gt; fork, which I would recommend to most users. Only those who need its deep colors features should consider sticking with the old and tired ImageMagick.&lt;/p&gt;

&lt;h4 id=&quot;graphicsmagick-mit&quot;&gt;GraphicsMagick (MIT)&lt;/h4&gt;

&lt;p&gt;If you are needing to process images in batch, &lt;a href=&quot;http://www.graphicsmagick.org/&quot;&gt;GraphicsMagick&lt;/a&gt; is your starting shortstop. Its use of OpenMP means that CPU-bound tasks scale linearly as processor cores are added.&lt;/p&gt;

&lt;h3 id=&quot;playback&quot;&gt;Playback&lt;/h3&gt;

&lt;h4 id=&quot;mpv&quot;&gt;mpv&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/mpv.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The VideoLan folks have always done a fantastic job with the VLC player, however if you are serious about working with media you’ll want to move on over to the new king of FOSS media playback, &lt;code class=&quot;highlighter-rouge&quot;&gt;mpv&lt;/code&gt;. Those 10-bit color anime folks love it, so you know it must be good.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mpv&lt;/code&gt; has a world-class plugin system that enables users to contribute scripts and plugins in either Lua and NodeJS. This is very useful for media analysis and for media processing automation.&lt;/p&gt;

&lt;h3 id=&quot;video&quot;&gt;Video&lt;/h3&gt;

&lt;p&gt;Video encoding and DSP today is largely centralized within the FFmpeg project, however more advanced operations will require additional tooling.&lt;/p&gt;

&lt;h4 id=&quot;ffmpeg-lgplgplnon-free&quot;&gt;FFmpeg (LGPL/GPL/non-free)&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://ffmpeg.org&quot;&gt;FFmpeg&lt;/a&gt; is one the most significant and prolific FOSS projects out there today. Known as the “Swiss Army Knife” of multimedia coding, FFmpeg is an indispensible tool for your media workflow, and will likely be a dependency for building many other great media tools.&lt;/p&gt;

&lt;p&gt;You’d be pretty crazy to attempt any video work within the FOSS ecosystem without a recent build of FFmpeg.&lt;/p&gt;

&lt;h4 id=&quot;vapoursynth-lgpl&quot;&gt;VapourSynth (LGPL)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/vs.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Many think that &lt;em&gt;if you can’t do it in FFmpeg, it probably can’t be done&lt;/em&gt;, but that’s probably because they don’t know about &lt;a href=&quot;http://www.vapoursynth.com/&quot;&gt;Vapoursynth&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;VapourSynth is a powerful open source Python framework for advanced video frame processing and other visual DSP operations. It’s got some of the best post-production and color tooling out there, and a really healthy community of video freak contributors who dogfood their own work in meaningful ways. It is in many ways a replacement for the aging, less-performant AviSynth framework.&lt;/p&gt;

&lt;p&gt;A few notes about VapourSynth… first, this is definitely software developed by &lt;em&gt;media engineers&lt;/em&gt;, so you will discover bugs. Expect releases to come out very frequently, and definitely don’t skip reading the docs. Also, some operations on VapourSynth will take a &lt;em&gt;hilariously&lt;/em&gt; long amount of time to complete, though the results are often worth the wait.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Distributed Media's Ancient Origins</title>
   <link href="https://grathwohl.me/2019/11/04/distributed-media"/>
   <updated>2019-11-04T07:00:00-05:00</updated>
   <id>https://grathwohl.me/2019/11/04/Distributed-Media</id>
   <content type="html">&lt;blockquote&gt;
  &lt;p&gt;This article originally appeared on the &lt;a href=&quot;https://medium.com/ara-blocks&quot;&gt;ARA Medium channel&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;how-a-two-million-year-old-event-helped-us-build-the-future&quot;&gt;How A Two-Million Year Old Event Helped Us Build the Future&lt;/h2&gt;

&lt;p&gt;As 2019’s ongoing streaming media wars continue to heat up, technologists peering around the corner are beginning to see the distinct advantages in decentralizing and distributing our media workflows. The rise of AT&amp;amp;T’s WarnerMedia and Oath’s transformation into Verizon Media signal that the world of content creation is already undergoing a significant shift in distribution practices.&lt;/p&gt;

&lt;p&gt;As a result, we are now entering a time where content is no longer &lt;em&gt;merely&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=kums8SGXHoo&quot;&gt;&lt;em&gt;king&lt;/em&gt;&lt;/a&gt;. Content has become the &lt;a href=&quot;https://www.emarketer.com/content/average-us-time-spent-with-mobile-in-2019-has-increased&quot;&gt;soil under our feet&lt;/a&gt;, the &lt;a href=&quot;https://www.businessinsider.com/how-much-tv-do-americans-watch-2016-6&quot;&gt;air we breathe&lt;/a&gt;, and the &lt;a href=&quot;https://everysecond.io/youtube&quot;&gt;water we drink&lt;/a&gt;. It ceases to serve as a mere authority in the world — it is now &lt;em&gt;the&lt;/em&gt; authority of the world — and any person, group, or brand who wishes to reach its target audience must participate by means of content creation.&lt;/p&gt;

&lt;p&gt;Today, content creation is embraced by more people than ever before. That’s why at &lt;a href=&quot;https://ara.one&quot;&gt;&lt;strong&gt;Ara&lt;/strong&gt;&lt;/a&gt;, we’re building out the distributed content network that will benefit all content creators, both new and seasoned, by removing third parties, reducing hosting costs, and providing a powerful new way to reward participation in content delivery.&lt;/p&gt;

&lt;h2 id=&quot;the-inevitability-of-decentralization--distribution&quot;&gt;The Inevitability of Decentralization &amp;amp; Distribution&lt;/h2&gt;

&lt;p&gt;Early on, we saw that distributed digital content networks would be the wave of the future, and today, we see their coming decentralization as an inevitability.&lt;/p&gt;

&lt;p&gt;History has shown us that popular media tends to undergo two transitions as it evolves from a new art into a ubiquitous aspect to everyday life: first, it &lt;strong&gt;decentralizes&lt;/strong&gt; from its initial authority; then, it becomes &lt;strong&gt;distributed&lt;/strong&gt;. Once a media is &lt;strong&gt;distributed&lt;/strong&gt;, the lines start to blur between producer and consumer. The evolution of video entertainment provides ample evidence in favor of this observation.&lt;/p&gt;

&lt;p&gt;After spending decades centralized around the movie theater chains, video entertainment began to &lt;strong&gt;decentralize&lt;/strong&gt; in the late 1940s, thanks to the development of new technology that made video easier to capture, edit, and distribute. The television industry formed around these new innovations, and as a result, video’s customer base expanded significantly, dethroning the movie theater chains as the central authority in video. By 1952, there were 20 million television sets installed in homes throughout the United States, vastly exceeding the number of movie theaters.&lt;/p&gt;

&lt;p&gt;Of course, after cable TV had its go at expanding the industry even further, the internet continued video’s decentralization. New entrants like Netflix, YouTube and Twitch have brought both the cinema and broadcast TV alike into our homes, leading to today’s unquestionable arrival of &lt;strong&gt;distributed&lt;/strong&gt; video. However, anyone who’s read the news lately would likely agree: our ambitions in distributed media far outpace society’s readiness for it.&lt;/p&gt;

&lt;p&gt;That is why the future will run on the infrastructure we build out today, otherwise we’ll struggle to meet our newfound content needs in a few short years. At &lt;strong&gt;Ara&lt;/strong&gt; we’ve been hard at work designing a distributed framework specifically addressing content delivery. Throughout this process, we’ve found ourselves taking inspiration from some rather unlikely sources — among them, the discovery of fire. The reasons for fire’s timeless prevalence throughout human history serves as an ample springboard for figuring out how to encourage and reward participation in a future dominated by distributed media.&lt;/p&gt;

&lt;h2 id=&quot;fire-the-ultimate-first-mover-advantage&quot;&gt;Fire: The Ultimate First-Mover Advantage&lt;/h2&gt;

&lt;p&gt;Nearly two million years ago, some nameless genius made history by building the world’s very first campfire. That individual could have never dreamed of what they were making possible with this one act of brilliance. The discovery of fire did much more than help us cook our food, produce light amidst the darkness, and protect us from predators. Fire opened up the very first creative possibilities for all human beings, giving us a means to achieve brilliance in nearly every aspect of culture.&lt;/p&gt;

&lt;p&gt;Think about it: before we could huddle into small tribes, feeling sheltered and safe under the watchful eye of a roaring flame, how were we to ever come up with such relatively &lt;em&gt;frivolous&lt;/em&gt; ideas as singing, storytelling, and dancing? Without the ability to control light, who would ever bother trying to draw, paint, or write?&lt;/p&gt;

&lt;p&gt;Mark Zuckerberg, Steve Jobs, and even Gutenberg all cower under the awesomely epic shadow cast by that one anonymous hero, who dragged all of our ancestors out of the caves and into the &lt;a href=&quot;https://www.tesla.com/blog/introducing-software-version-10-0&quot;&gt;Netflix-equipped self-driving electric cars&lt;/a&gt; in which we find ourselves today.&lt;/p&gt;

&lt;p&gt;Even though fire has proved itself to be overwhelmingly valuable, no one central authority has ever controlled fire. In this sense, the control of fire was humanity’s very first form of distributed media, and the campfire is its earliest and most enduring implementation. By merely providing light and heat, campfires generate &lt;em&gt;community&lt;/em&gt;, &lt;em&gt;participation&lt;/em&gt;, &lt;em&gt;trust&lt;/em&gt; and &lt;em&gt;safety&lt;/em&gt; — precisely the same qualities that underpin successful distributed content networks.&lt;/p&gt;

&lt;h2 id=&quot;community&quot;&gt;Community&lt;/h2&gt;

&lt;p&gt;Gathering around the fire with friends and family is most certainly one of life’s basic pleasures. This is because for millennia, humans have relied on their communities to survive and thrive, and fire has always played an essential role within those communities. Reliance upon fire goes well beyond the obvious benefits of warmth, light, and protection — without it, early societies would have had a much harder time developing their cultural arts, traditions, and values.&lt;/p&gt;

&lt;p&gt;Community provides a fertile audience for the expression of ideas, the capability for individual specialization, and the pride gained through participating in something bigger than oneself. Successful distributed media protocols such as BitTorrent have always relied upon an active and welcoming community to maintain their dominance. Those communities came about by both projects’ decisions to open source their code, which enabled them to be available on nearly every platform imaginable, supported by every operating system, and implementable in all sorts of other useful projects. This in turn has led to innovations such as &lt;a href=&quot;https://webtorrent.io/&quot;&gt;WebTorrent&lt;/a&gt;, breathing new life into this already outstanding web protocol.&lt;/p&gt;

&lt;p&gt;Ara has followed in these projects’ footsteps by &lt;a href=&quot;https://medium.com/@arablocks/why-were-choosing-open-source-9df789230d0a&quot;&gt;being an open source product&lt;/a&gt; from day one. But there are many ways where we can, and should improve upon today’s state of affairs. Ara uniquely fosters community around digital content by rewarding users for helping to distribute the movies, shows, music, and games that they’ve purchased. Unlike the users of BitTorrent or Bitcoin, users of Ara know that every time they receive a reward for sharing with their peers, they’ve just helped their favorite content creators achieve success, too.&lt;/p&gt;

&lt;h2 id=&quot;participation&quot;&gt;Participation&lt;/h2&gt;

&lt;p&gt;While gathering around the fire is a great way to foster community, without modes of participation, individuals will begin to fall out from that community rather quickly. Consider how one must participate in keeping a campfire continually lit, by adding more kindling and stoking the flame. Since nobody can gather kindling and light a fire at the same time, specialization and division of labor quickly emerged into the human consciousness. As a result, people take on individual responsibilities, both to the fire and to the activities surrounding it.&lt;/p&gt;

&lt;p&gt;Without avenues for individualized participation, communities stagnate and break apart. That’s why Ara has prioritized enabling participation from as many different parties as possible, without sacrificing ease of use. Creators, publishers, businesses, and fans all play a key role in enabling success, and one’s technical know-how should not limit one’s ability to participate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Creators&lt;/strong&gt; regain control over their content, deciding for themselves how they’d like to package, prepare, and deliver it to fans. Our free, open source &lt;a href=&quot;https://ara.one/app&quot;&gt;Ara File Manager&lt;/a&gt; allows anyone to become a content creator, and under whatever terms they’d like!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Publishers&lt;/strong&gt; leverage finer-grained control over content licensing and DRM, enabling innovative new approaches to digital licensing and distribution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Businesses&lt;/strong&gt; are able to integrate Ara’s technology to power their content delivery, significantly reducing costs for the entire digital content ecosystem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fans&lt;/strong&gt; enjoy the opportunity to be able to truly “vote with their dollars” again and contribute in a positive way to their favorite artists’ careers, without having to sit through any advertisements or have their usage tracked.&lt;/p&gt;

&lt;h2 id=&quot;trust-and-safety&quot;&gt;Trust and Safety&lt;/h2&gt;

&lt;p&gt;Early humans used their control over fire to protect themselves from dangerous predators, other hostile tribes of humans, and from the natural elements. The illuminating flame helped quickly identify newcomers during nighttime, providing a reliable means for quickly establishing trust.&lt;/p&gt;

&lt;p&gt;A distributed framework flourishes based upon its ability to gain trust among both current participants and potential new entrants. At Ara, we leverage blockchain technology to ensure objective, unquestionable transaction records, which can be publicly verified by anybody. What better way to check whether your favorite filmmaker received your payment for their latest movie?&lt;/p&gt;

&lt;p&gt;Without powerful safety mechanisms and an in-built system of trust, distributed media just feels a whole lot riskier. That’s why we built &lt;a href=&quot;https://arablocks.github.io/guides/#/ara-identity&quot;&gt;Ara Identity&lt;/a&gt;, which offers a powerful, foolproof way to ensure the validity and identity of peers. This not only helps to harden our network against potential security vulnerabilities — it also eliminates the chances for identity theft, payment scamming, and other fraud which has plagued online commerce from the get-go.&lt;/p&gt;

&lt;p&gt;Ara’s outstanding encryption implementation means your content purchasing records are incredibly safe. We leverage the same encryption technology as the &lt;a href=&quot;https://www.newsweek.com/bad-news-fbi-edward-snowdens-favorite-chat-app-signal-just-got-50m-funding-816035&quot;&gt;Snowden-approved&lt;/a&gt; Signal messaging app. Since all our encryption technology was built into the protocol from the very start, users will not need to learn any new security tricks or jump through any new hoops just to be protected. That’s a win for all parties involved, without a doubt.&lt;/p&gt;

&lt;h2 id=&quot;innovation-through-tradition&quot;&gt;Innovation Through Tradition&lt;/h2&gt;

&lt;p&gt;Sometimes, we are able to make extraordinary things happen by paying attention to the successes of the past. Even though today’s world feels seemingly detached from the campfires of our ancestors, much of what we know and trust about the world came about through their use. By applying the campfire’s virtues to the exciting new developments in distributed media, we have instilled sanity, reliability, and innovation all into one simple protocol.&lt;/p&gt;

&lt;p&gt;Though we may never obtain the ubiquity of fire, Ara is blazing an exciting new trail in content networks, and we invite each and every one of you to join us on our journey. Visit &lt;a href=&quot;https://ara.one&quot;&gt;https://ara.one&lt;/a&gt; to learn more.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Audio Mastering Workflow for Linux</title>
   <link href="https://grathwohl.me/2019/05/05/linuxmasteringflow-1"/>
   <updated>2019-05-05T12:15:00-04:00</updated>
   <id>https://grathwohl.me/2019/05/05/linuxmasteringflow_1</id>
   <content type="html">&lt;p&gt;This series of posts will detail the audio mastering workflow I employ on my main Linux workstation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Watercooled Full ATX Tower&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Intel i9 @ 4.2Ghz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;64GB ECC RAM&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Arch Linux with the &lt;code class=&quot;highlighter-rouge&quot;&gt;linux-rt&lt;/code&gt; kernel patches&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.rme-audio.de/en/products/hdsp_9632.php&quot;&gt;RME Hammerfall DSP 9632&lt;/a&gt; PCI Audio Card&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://babyface.rme-audio.de/&quot;&gt;RME Babyface Pro&lt;/a&gt; USB Audio Interface&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why&quot;&gt;Why?&lt;/h2&gt;

&lt;p&gt;The answer is simple: &lt;em&gt;Linux provides the best audio engineering workflow for audio professionals - hands down.&lt;/em&gt; Don’t believe me? I’ll prove it!&lt;/p&gt;

&lt;h3 id=&quot;audio-engine&quot;&gt;Audio Engine&lt;/h3&gt;

&lt;p&gt;Audio is a second-class citizen in every modern OS. From macOS’s progressively-worsening “CoreAudio” to Windows’ pathetic ASIO implementation, the proprietary software world has fewer reasons every day to coerce you into a non-free software environment.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://jackaudio.org/&quot;&gt;JACK&lt;/a&gt; allows audio to be your OS’s main consideration.&lt;/p&gt;

&lt;p&gt;It lets you route &lt;em&gt;anything&lt;/em&gt; to &lt;em&gt;any other thing&lt;/em&gt; and does so at minimal to no latency!&lt;/p&gt;

&lt;h3 id=&quot;extensibility-without-compromise&quot;&gt;Extensibility Without Compromise&lt;/h3&gt;

&lt;p&gt;Want to add a new source connection or a track insert? Audio doesn’t stop playing and no clicks are emitted just because you wanted to do that.&lt;/p&gt;

&lt;p&gt;Want to use Wine to power your Windows VSTs inside your DAW? There’s an application for that.&lt;/p&gt;

&lt;p&gt;Want to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;realtime&lt;/code&gt; kernel patches to ensure your latency never extends beyond 1.9ms? Just &lt;code class=&quot;highlighter-rouge&quot;&gt;yay -S linux-rt&lt;/code&gt; and go brew some coffee. Within an hour you should have a fully functioning realtime kernel OS with incredible latency features. And trust me, you &lt;em&gt;do&lt;/em&gt; want to use &lt;code class=&quot;highlighter-rouge&quot;&gt;linux-rt&lt;/code&gt;. Anyone who tells you that audio engineers won’t benefit from using realtime patches doesn’t in any way understand our plight. Using &lt;code class=&quot;highlighter-rouge&quot;&gt;linux-rt&lt;/code&gt; I am able to achieve latencies under 2ms at 44.1kHz with 3 periods per block, using my RME Babyface Pro in Class-Compliant Mode.&lt;/p&gt;

&lt;h2 id=&quot;how&quot;&gt;How?&lt;/h2&gt;

&lt;p&gt;It actually is quite simple. However, I do have to call out a caveat:&lt;/p&gt;

&lt;h3 id=&quot;caveat&quot;&gt;CAVEAT&lt;/h3&gt;

&lt;p&gt;The system I’ve configured and which has been successful for me, is by no means an “all rounder”. By this, I mean that users must go to some lengths to ensure that no extraneous processes are running, no systemd services are operational, etc., unless &lt;em&gt;it is absolutely necessary&lt;/em&gt; for your audio tasks.&lt;/p&gt;

&lt;p&gt;If you use &lt;code class=&quot;highlighter-rouge&quot;&gt;linux-rt&lt;/code&gt; expecting the same stability for, say, databases and video processing, you’ll be very disappointed. To do this work, simply boot back into the stable &lt;code class=&quot;highlighter-rouge&quot;&gt;linux&lt;/code&gt; kernel that comes with your Arch Linux installation.&lt;/p&gt;

&lt;h3 id=&quot;getting-started&quot;&gt;Getting Started&lt;/h3&gt;

&lt;p&gt;To get started, simply install a new Arch Linux base OS on your audio PC.&lt;/p&gt;

&lt;p&gt;Next, compile the &lt;code class=&quot;highlighter-rouge&quot;&gt;linux-rt&lt;/code&gt; sources by installing the &lt;code class=&quot;highlighter-rouge&quot;&gt;yay&lt;/code&gt; AUR helper, then runnning:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yay -S linux-rt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You should also acquire the following realtime-oriented tools:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yay -S rtapp rtirq realtime-suggestions cpupower
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;recommended-settings&quot;&gt;Recommended Settings&lt;/h5&gt;

&lt;p&gt;Enable the realtime services to run at boot:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl enable rtapp &amp;amp;&amp;amp; systemctl start rtapp
systemctl enable rtirq &amp;amp;&amp;amp; systemctl start rtirq
systemctl enable cpupower &amp;amp;&amp;amp; systemctl start cpupower
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Open the &lt;code class=&quot;highlighter-rouge&quot;&gt;rtapp&lt;/code&gt; config file at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/rtapp/rtapp.conf&lt;/code&gt; and add any binaries for audio programs you use there.&lt;/p&gt;

&lt;p&gt;Set swappiness lower than default by running:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo sysctl vm.swappiness=10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Set the CPU governor to &lt;code class=&quot;highlighter-rouge&quot;&gt;performance&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo cpupower frequency-set -g performance
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, run the &lt;code class=&quot;highlighter-rouge&quot;&gt;realtime-suggestions&lt;/code&gt; program to see what it thinks about your configuration. It will give you warnings if anything should change.&lt;/p&gt;

&lt;h3 id=&quot;software&quot;&gt;Software&lt;/h3&gt;

&lt;h4 id=&quot;jack2--cadence&quot;&gt;JACK2 &amp;amp; Cadence&lt;/h4&gt;

&lt;p&gt;We will be using &lt;code class=&quot;highlighter-rouge&quot;&gt;jack2&lt;/code&gt; because using &lt;code class=&quot;highlighter-rouge&quot;&gt;jack&lt;/code&gt; in 2019 is stupid! The multi-threading, MIDI, and other various features of &lt;code class=&quot;highlighter-rouge&quot;&gt;jack2&lt;/code&gt; are deal-breakers, not nice-to-haves.&lt;/p&gt;

&lt;p&gt;Also we will use &lt;code class=&quot;highlighter-rouge&quot;&gt;cadence&lt;/code&gt; to configure our JACK settings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kx.studio/screenshots/cadence1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Get everything you need by running:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yay -S jack2 cadence alsa-firmware alsa-utils alsa-tools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;recommended-settings-1&quot;&gt;Recommended Settings&lt;/h5&gt;

&lt;p&gt;For any high-performance real-time audio synthesis work, such as SuperCollider programming, it’s strongly encouraged that you run at the lowest sampling frequency possible (I use 44.1kHz and if you use anything higher, you need to &lt;a href=&quot;https://xiph.org/video/vid2.shtml&quot;&gt;watch this video&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;I am able to place my RME Babyface Pro at 44.1kHz with a 3-period buffer and a block latency of 64 which results in a final round-trip latency of 1.5ms!!! That’s right - on consumer hardware, I am running an audio workstation that has a round-trip of under two milli-freaking-seconds! It’s a great time to be an audio engineer.&lt;/p&gt;

&lt;h4 id=&quot;non-daw&quot;&gt;non-daw&lt;/h4&gt;

&lt;p&gt;I love &lt;code class=&quot;highlighter-rouge&quot;&gt;non-daw&lt;/code&gt;. It’s a modular DAW which allows one to roll their own audio workflows.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;non&lt;/code&gt; comes with:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;non-mixer&lt;/code&gt;: A super fast audio mixing engine. It’s got an extremely functional &lt;a href=&quot;http://non.tuxfamily.org/mixer/doc/spatialization-console.png&quot;&gt;spatial panner&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;non-session-manager&lt;/code&gt;: A session management interface which handles all plugin states, audio interconnections, and routing specifications.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;non-sequencer&lt;/code&gt;: A midi and audio file tracking sequencer which is serviceable for most uses as long as you’re not looking to become a Venetian Snares copycat. It’s got this novel concept of a “phrase” which is essentially a way to break down compositions into units of musical gestures.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;non-timeline&lt;/code&gt;: A multi-track timeline view which enables lining up all your tracks, components, and outputs, unified by a single clock.&lt;/p&gt;

&lt;p&gt;For mastering purposes, I have installed the following:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yay -S non-mixer non-session-manager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;carla-vst-bridge&quot;&gt;Carla: VST Bridge&lt;/h4&gt;

&lt;p&gt;Carla is the software that allows us to run our Windows VST plugins (which we have &lt;strong&gt;PAID FOR&lt;/strong&gt; of course) in Linux without any sacrifices in terms of quality, efficiency, or reliability.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/20961a44e99d7a813837fa1ab5c3ab2395809428/687474703a2f2f6b7873747564696f2e6c696e7578617564696f2e6f72672f73637265656e73686f74732f6361726c612e706e67&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before installing Carla, let’s prepare our system:&lt;/p&gt;

&lt;p&gt;First step is to make sure we are reading from Arch’s &lt;code class=&quot;highlighter-rouge&quot;&gt;multilib&lt;/code&gt; repo. To do that, uncomment the multilib repository information in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/pacman.conf&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next, we install wine: &lt;code class=&quot;highlighter-rouge&quot;&gt;yay -S wine-staging&lt;/code&gt;. It is critical that you use &lt;code class=&quot;highlighter-rouge&quot;&gt;wine-staging&lt;/code&gt; from the AUR and not the production-ready wine binary, because only &lt;code class=&quot;highlighter-rouge&quot;&gt;wine-staging&lt;/code&gt; supports running VST plugins in RT mode.&lt;/p&gt;

&lt;p&gt;Now you can install carla and all the necessary modules:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;yay -S carla-git carla-bridges&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now, you can use Carla to load Windows VST2 and VST3s (both 32bit and 64bit supported) &lt;a href=&quot;https://kx.studio/Applications:Carla#Usage&quot;&gt;with ease&lt;/a&gt;!&lt;/p&gt;

&lt;h5 id=&quot;recommended-settings-2&quot;&gt;Recommended Settings&lt;/h5&gt;

&lt;p&gt;For mastering, run Carla’s engine is in &lt;em&gt;continuous rack&lt;/em&gt; mode. This allows a user to order their plugins like on a physical audio rackmount cabinet, and handles all audio routing and latency concerns for you. The tradeoff is that since this is a simplified routing approach, advanced features like infinite patchbay routing are not available to you. But for mastering purposes, this is usually irrelevant.&lt;/p&gt;

&lt;h2 id=&quot;conclusion--up-next&quot;&gt;Conclusion / Up Next&lt;/h2&gt;

&lt;p&gt;This concludes &lt;em&gt;Part 1&lt;/em&gt; of this series of posts. You should now be able to run your new Arch Linux install in &lt;code class=&quot;highlighter-rouge&quot;&gt;realtime&lt;/code&gt; mode, achieving incredible latencies without risking system stability. And you should even be able to run your Windows VSTs within your Arch system by utilizing &lt;code class=&quot;highlighter-rouge&quot;&gt;wine-staging&lt;/code&gt;!&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Part 2&lt;/em&gt; of this series, I’ll demonstrate how to manage your audio signal flows, custom routing, plugin states, and more. We’ll also introduce the concepts of MIDI and OSC communication with &lt;code class=&quot;highlighter-rouge&quot;&gt;jack2&lt;/code&gt; and the ALSA framework so that you can use your interface hardware to interact with Ardour5, non-daw, etc.&lt;/p&gt;

&lt;p&gt;All of the musical and audio engineering work I do originates from my Linux audio systems. Check out what I’ve achieved using only free and open source software, at the &lt;a href=&quot;https://multipli.city&quot;&gt;Sonic Multiplicities homepage&lt;/a&gt;. You can hear many of my mastering projects at &lt;a href=&quot;https://soundcloud.com/sacreddata&quot;&gt;my old company’s SoundCloud account&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Participation: Digital Media's Missing Ingredient</title>
   <link href="https://grathwohl.me/2018/11/15/participation-digital-media"/>
   <updated>2018-11-15T05:44:00-05:00</updated>
   <id>https://grathwohl.me/2018/11/15/Participation_Digital_Media</id>
   <content type="html">&lt;iframe src=&quot;https://docs.google.com/presentation/d/e/2PACX-1vQArwmb8OTVs-eBaUDXaj7XgIPdAkGPvBGYuW5nQWezFNsdeP-alDbX9cvaQRp5UoiQ3p4xSVMT47sm/embed?start=true&amp;amp;loop=false&amp;amp;delayms=30000&quot; frameborder=&quot;0&quot; width=&quot;720&quot; height=&quot;480&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;
</content>
 </entry>
 
 <entry>
   <title>Playing Your Audible Audiobooks In Linux</title>
   <link href="https://grathwohl.me/2018/09/10/audibleffmpeg"/>
   <updated>2018-09-10T06:44:00-04:00</updated>
   <id>https://grathwohl.me/2018/09/10/audibleffmpeg</id>
   <content type="html">&lt;p&gt;If you want to convert an Audible .aax file into a less restrictive file format, you can do so with ease using &lt;a href=&quot;https://ffmpeg.org/&quot;&gt;FFmpeg&lt;/a&gt;, one of my all-time favorite GPL projects.&lt;/p&gt;

&lt;p&gt;Navigate to the directory where the .aax file is that you’d like to test on, and perform the following on the command line:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ffmpeg -activation_bytes 1CEB00DA -i test.aax -vn -c:a copy output.mp4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing this creates an mp4 container with only an AAC audio stream inside. By adding the &lt;code class=&quot;highlighter-rouge&quot;&gt;-c:a copy&lt;/code&gt; argument, we’re telling FFmpeg to do a stream copy of the audio, negating the need to compress and process the audio again. Since Audible audio is encoded at 64kbps HE-AAC or lower, this argument is essential to retain quality!&lt;/p&gt;

&lt;p&gt;This MP4 can now be played on any conventional audiovisual playback software that supports the MP4 container file. Enjoy!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hacking Isn’t Searching; It’s Quartering</title>
   <link href="https://grathwohl.me/2018/06/25/hacking-is-quartering"/>
   <updated>2018-06-25T08:00:00-04:00</updated>
   <id>https://grathwohl.me/2018/06/25/Hacking-Is-Quartering</id>
   <content type="html">&lt;p&gt;A common critique of the deep state’s dragnet surveillance operation is to depict it as a violation of the Fourth Amendment. The pundits and politicians who publicly railed against the recent NSA and FBI revelations commonly referred to the issue as one of “warrant-less” wiretapping, data collection, and spying.&lt;/p&gt;

&lt;p&gt;But that isn’t quite the game that signals intelligence analysts and network security experts are playing.&lt;/p&gt;

&lt;p&gt;The invocation of the term “warrant-less” is unsurprising; it hearkens back to the Watergate scandal, and by making that comparison, it helps to make the case that these surveillance programs were just as serious and important as that major kerfuffle back in 1972.&lt;/p&gt;

&lt;p&gt;The issue with this is that bugging a hotel room and tampering with evidence are such benign and irrelevant acts compared with what the NSA does routinely. In reality, recent dragnet surveillance revelations are far more destructive, wide-ranging, and horrifying than anything Richard Nixon was capable of doing. The NSA does not fuck around.&lt;/p&gt;

&lt;p&gt;Though a well-intended PR trick, the term “warrant-less” does more to downplay the seriousness of governmental dragnet surveillance than it wakes up the general populace. Likening the NSA’s work to merely a search or seizure of evidence significantly misinforms the public about the nature of hacking in a number of ways. Let’s pick them apart, shall we?&lt;/p&gt;

&lt;h3 id=&quot;the-nsa-plays-offense-not-defense&quot;&gt;The NSA Plays Offense, Not Defense&lt;/h3&gt;

&lt;p&gt;Perhaps most important to remember is that the NSA is part of the Department of Defense; it is a military organization, not law enforcement.&lt;/p&gt;

&lt;p&gt;In almost every instance, hacking a network or device is not an act of defense, but rather an act of offense. When done by the NSA, you can expect it to be a particularly aggressive act — not one to conduct law enforcement activities, but to steal secrets, or to weaponize computing and network hardware.&lt;/p&gt;

&lt;p&gt;When a three-letter agency breaks into the system of the Average Joe, that person is usually not the target. Their system was merely a means to some other more dastardly end. For example, a compromised system is often leveraged by the attacker against their agency’s final target, which is often some other state actor. Worse yet, when these attacks are carried out, there’s no guarantee that the agency has masked your private information from the device. So if the target on the other end is capable, they may “hack back,” leaving ordinary citizens right in the crossfire.&lt;/p&gt;

&lt;h3 id=&quot;theres-no-warrant-for-committing-atrocities&quot;&gt;There’s No Warrant for Committing Atrocities&lt;/h3&gt;

&lt;p&gt;Once they gain access to your machine, there are many things that the NSA’s goons can do, and almost all of them are illegal to do in any circumstance no matter who you are, warrant or otherwise. These continued violations of our Constitution’s fundamental protections resembles nothing short of a human rights atrocity.&lt;/p&gt;

&lt;p&gt;Some different types of these egregious attacks include:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Denial of Service: Overloading a device or network with falsified activity, for the purpose of bringing down critical functionality. This could be as inconsequential as a kid pulling the fire alarm at their middle school, or could be as deadly as an aerial assault by a bomber jet. It all depends on the infrastructure that was attacked and the users impacted by the attack. Either way, it is a crime that cannot be excused by a warrant from a judge.
Subversion: Involves the manipulation or degradation of data, in order to incite lowered confidence in the integrity of the information the network provides. This is ultimately a form of PSYOPS — psychological warfare. On the one hand, we routinely criticize Russia for engaging in this kind of activity against the US. On the other hand, we conceive of such warfare as a form of cruel and unusual punishment when it is used against American citizens. This dual narrative could even be seen as the NSA engaging in an ongoing subversion attack against the American people.
Masquerade: When an attacker elevates their own permissions/privileges within a computer system in order to leverage credentials to which they should not have access. Imagine if a person broke into the local police headquarters, armed themselves in official gear and a police badge, and then used that false authority to intimidate their enemies. I would hope that no judge on this planet would grant a warrant for such an activity.
Forgery: When an attacker dispatches messages from a computer network, pretending to be somebody they aren’t. This is the kind of attack that would happen if a Subversion and a Masquerade had a baby. It involves masquerading as a different computer user in order to subvert the computer system’s messaging systems. Forgery is a state and federal crime in all US jurisdictions.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;could-the-constitution-still-be-helpful&quot;&gt;Could the Constitution Still Be Helpful?&lt;/h3&gt;

&lt;p&gt;So no, the Fourth Amendment doesn’t have a whole lot to say about the NSA’s activities. Luckily, unlike most of our current elected officials, the Founding Fathers were not idiots. The Bill of Rights still can be of major assistance in the fight against the offensive cyber operations of our military. We just need to rethink which amendment to focus upon.&lt;/p&gt;

&lt;p&gt;There is only one amendment to the Constitution that addresses the relationship between the citizenry and the military — the Third Amendment. And it is stunningly apt in helping to make sense of exactly why the NSA’s actions are so objectionable.&lt;/p&gt;

&lt;p&gt;The Third Amendment reads as follows, with my own emphases:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;No Soldier shall, in time of peace be quartered in any house, without the consent of the Owner, nor in time of war, but in a manner to be prescribed by law.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;citizens-1-military-0&quot;&gt;Citizens: 1. Military: 0.&lt;/h3&gt;

&lt;p&gt;As an American, your private property rights as they pertain to the military are quite clear: your rights are superior to theirs. During peace time, the federal government’s soldiers cannot commandeer, lodge themselves into, or otherwise tamper with your property just to carry out their missions.&lt;/p&gt;

&lt;p&gt;In a time of war Congress would need to vote to approve explicitly what kind of quartering must be allowed by citizens, and that hasn’t happened yet. This is moot anyway, because we aren’t in a time of war, nor have we been since WWII.&lt;/p&gt;

&lt;h3 id=&quot;hey-dummy-it-says-house-not-computer&quot;&gt;Hey Dummy! It Says “House,” not “Computer”&lt;/h3&gt;

&lt;p&gt;Some may object to using the term “house” to describe a computer. But it is certainly reasonable to consider a computer under this definition. These days, many individuals have more of their lives inside of their personal computing devices — their PCs, smartphones, and Fitbits — than inside their actual domiciles. Modernity has even brought us to a point where the concept of the digital nomad is an actual thing.&lt;/p&gt;

&lt;p&gt;Still not convinced?&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Where do you read the majority of your news — online, or in the newspaper?
Where do you have more photos stored — on your smartphone, or in physical photo albums?
Where are the majority of your 2017 financial documents and records stored — a computer, or a filing cabinet?
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Exactly.&lt;/p&gt;

&lt;h3 id=&quot;this-is-an-important-amendment-that-most-people-forget-about&quot;&gt;This is an Important Amendment that Most People Forget About&lt;/h3&gt;

&lt;p&gt;The Third Amendment was briefly debated before the ratification of the US Constitution, because the consensus was broad: we had to make sure that the Quartering Acts could not happen again. They were, after all, one of the primary tensions that led to the American Revolution in the first place. The Founders knew that the forceful quartering of an occupying force was no burden to force onto a free citizenry.&lt;/p&gt;

&lt;p&gt;Perhaps this is why the Third Amendment is so stunningly broad in its definition. Its text begins by placing a restriction on the soldier, so the Third Amendment grants not a positive right per se, but rather a negative right — one that explicitly restricts the actions that may be taken by a soldier of the US. It then goes on to state that it protects the rights of the owner of any house, which means that the house need not even exist on American soil to be protected.&lt;/p&gt;

&lt;h3 id=&quot;what-now&quot;&gt;What Now?&lt;/h3&gt;

&lt;p&gt;What we are trying to stop here is not the mere digital canoodling of the local police or even the FBI. This isn’t an effort to thwart the CIA’s numerous cyber warfare tools exposed by WikiLeaks. What is at risk by not taking appropriate action with respect to the government’s violation of the Third Amendment is the continued sanctioning of their actions by the world’s citizens and, more troubling, the corporations they patronize.&lt;/p&gt;

&lt;p&gt;At the end of the day, the Third Amendment is a federal law that establishes behavioral requirements for the United States military — the very same group committing by far the most atrocious cyber offensives throughout the world. All because lawmakers, politicians, and yes, statistically even you — don’t understand a damn thing about cybersecurity and the evolving digital war frontier.&lt;/p&gt;

&lt;p&gt;What’s worse is that people know just as little about the way American government and law is designed to work, so most digital citizens are unprepared to grasp this proverbial double-edged sword from either end. That needs to change immediately. The best takeaway I could ask a layperson to have after considering this is that the ability to intelligently communicate about Constitutional law is something that computer experts and computer users alike must begin to take seriously. What we do for a living is not child’s play — even a child playing on an iPad is no longer mere child’s play. We all have something significant to lose if we lose our fight for our digital rights against the state.&lt;/p&gt;

&lt;p&gt;We could try to blame our broken education system for our citizens’ inability to grasp basic American civics. However, I’m sure most Americans agree by now that this once great and meaningful aspect to American life — our public education system — is a lost cause beyond any kind of meaningful repair.&lt;/p&gt;

&lt;h3 id=&quot;dont-consent&quot;&gt;Don’t Consent!!!&lt;/h3&gt;

&lt;p&gt;I don’t have any truly good advice about where to go from here. I’m not a lawyer, so nothing I say will be even close to helpful on a legal front. So, my best advice is simply: don’t consent.&lt;/p&gt;

&lt;p&gt;Make it abundantly, explicitly clear to any intruder into your network that you do not consent to their illegal activities, and that you would like them to exit your property immediately. This won’t help protect you against anything, but maybe if enough people start to do this, it will catch on, and then somebody with actual legal expertise could inform us on how to best proceed in getting our Third Amendment protections back in some legislative fashion.&lt;/p&gt;

&lt;p&gt;You can signal your lack of consent to an attacker by learning how to set your computer’s login “message of the day” — aka your /etc/motd file. Better yet, donate to the Electronic Frontier Foundation and get yourself some of these lovely stickers to proclaim your distrust of government surveillance in both the physical and digital realms.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>FFmpeg 3.0 Is Here</title>
   <link href="https://grathwohl.me/2016/02/14/ffmpeg3ishere"/>
   <updated>2016-02-14T23:11:00-05:00</updated>
   <id>https://grathwohl.me/2016/02/14/ffmpeg3ishere</id>
   <content type="html">&lt;p&gt;The team behind FFmpeg unveiled a major new release, “Einstein,” recently, and in the release notes appears a strongly-worded suggestion:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;(By the way, if you’re thinking that today may be the day to look into FFmpeg’s git master – don’t. Seriously, just don’t. This is no slight against the FFmpeg team - it’s just that with a project of this nature, you have to build the nightly release every day to get helpful suppo
rt. Developers are committing small patches to individual subsets of the FFmpeg project every day, which is why the release candidates are a sure bet for most folks.)&lt;/p&gt;

&lt;p&gt;There are many of you out there that run FFmpeg in production, so the team’s urgency to get users to update should be taken as an indication that big changes have come. Here’s some noteworthy entries in 3.0’s &lt;a href=&quot;https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=Changelog ;hb=n3.0&quot;&gt;release notes&lt;/a&gt;:&amp;lt;/p&amp;gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# This feature will allow content enterprises to create encrypted proxies of their sensitive content
- Common Encryption (CENC) MP4 encoding and decoding support
# The DXV codec is used in live visual performances (often referred to as VJing)
- DXV decoding
# Stereo audio processing tools like these hint at optimizing audio tracks for headphone listeners
- extrastereo filter
- stereowiden filter
- stereotools filter
# FFmpeg's AAC improvements mean fewer patent/royalty issues when creating canonical MP4s
- extensive native AAC encoder improvements and removal of experimental flag
# AcousticID generation for audio tracks!
- chromaprint fingerprinting muxer
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Sheesh! And that’s not even the half of it. Suffice to say, this FFmpeg release is a significant one. Ahead, I will explore the above-listed features in detail.&lt;/p&gt;

&lt;h2 id=&quot;common-encryption-support-for-mp4&quot;&gt;Common Encryption support for MP4&lt;/h2&gt;

&lt;p&gt;This feature is not documented on FFmpeg.org’s &lt;code class=&quot;highlighter-rouge&quot;&gt;ffmpeg-all.html&lt;/code&gt; page. After a quick trip to #ffmpeg on freenode, I discovered that no documentation currently exists for this feature except for on the command line:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ffmpeg -h muxer=mov | grep -encryption_scheme

# -encryption_scheme &amp;lt;string&amp;gt;     E....... Configures the encryption scheme, allowed values are none, cenc-aes-ctr
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Though a helpful start, I have not yet gotten this feature to work.&lt;/p&gt;

&lt;h2 id=&quot;chromaprint-support&quot;&gt;Chromaprint Support&lt;/h2&gt;

&lt;p&gt;Chromaprint’s AcousticID is an audio fingerprinting library. It’s pretty cool that they’ve implemented support for this within FFmpeg! There are some caveats, however. To generate an AcousticID of an audio file in FFmpeg, that file must be a &lt;code class=&quot;highlighter-rouge&quot;&gt;single 
signed native-endian 16-bit raw audio stream&lt;/code&gt;. Yikes!&lt;/p&gt;

&lt;h2 id=&quot;native-aac-codec&quot;&gt;Native AAC Codec&lt;/h2&gt;

&lt;p&gt;Word on the street was, at first, that the FFmpeg native aac codec is now outperforming the fdk-aac codec. I was dubious of this claim, and recently, a respected super mega-nerd over at Hydrogenaud.io released &lt;a href=&quot;https://hydrogenaud.io/index.php/topic,111085/topicseen.html&quot;&gt;his own thoughts&lt;/a&gt; on the newly-improved codec. Needless to say, &lt;em&gt;if you are updating to 3.0, do not get rid of libfdk-aac!&lt;/em&gt; The fdk-aac codec is still the only available FFmpeg aac library that truly supports VBR, and it still wins in the sound quality department.&lt;/p&gt;
</content>
 </entry>
 

</feed>
